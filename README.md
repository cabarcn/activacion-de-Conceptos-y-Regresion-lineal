[# activacion-de-Conceptos-y-Regresion-lineal

Proyecto educativo para **activar conceptos de Machine Learning** aplicando un flujo completo de **RegresiÃ³n Lineal** sobre el dataset `Credit.csv`.  
El objetivo es practicar **EDA**, **preprocesamiento**, **entrenamiento**, **evaluaciÃ³n** y **validaciÃ³n de supuestos** del modelo.

---

## ğŸ“Œ Tabla de contenido
- [Objetivos de aprendizaje](#-objetivos-de-aprendizaje)
- [Estructura del proyecto](#-estructura-del-proyecto)
- [Dataset](#-dataset)
- [Requisitos](#-requisitos)
- [CÃ³mo ejecutar](#-cÃ³mo-ejecutar)
  - [Google Colab](#google-colab)
  - [Local (Jupyter/VSCode)](#local-jupytervscode)
- [MÃ©tricas y validaciones](#-mÃ©tricas-y-validaciones)
- [PrÃ³ximos pasos (roadmap)](#-prÃ³ximos-pasos-roadmap)
- [Buenas prÃ¡cticas de reproducibilidad](#-buenas-prÃ¡cticas-de-reproducibilidad)
- [Contribuciones](#-contribuciones)
- [Licencia](#-licencia)
- [Autor](#-autor)

---

## ğŸ¯ Objetivos de aprendizaje
- Repasar el **pipeline** de ML: EDA - limpieza - ingenierÃ­a de variables - particiÃ³n de datos - modelado - evaluaciÃ³n.
- Entrenar y evaluar un modelo de **RegresiÃ³n Lineal**.
- Interpretar mÃ©tricas (**R2**, **MAE**, **MSE/RMSE**) y validar supuestos del modelo.
- Dejar un notebook reproducible para futuras iteraciones (regularizaciÃ³n, comparaciÃ³n de modelos, etc.).

____________________________________________________

> Si `Credit.csv` estÃ¡ por ahora en la raÃ­z del repo, puedes moverlo a `data/` o actualizar la ruta usada en el notebook (variable `DATA_PATH`).

---

## ğŸ§  Dataset
`Credit.csv` contiene variables financieras/demogrÃ¡ficas de clientes (ej.: ingresos, uso de crÃ©dito, edad, estado civil, etc.).  
La **variable objetivo** es continua (ej.: `Balance`), adecuada para regresiÃ³n.

- **Fuente**: material docente/ejercicio (indicar si existe una URL o autor especÃ­fico).
- **Campos**: documentar brevemente las variables mÃ¡s relevantes cuando se usen en el notebook.

---

## ğŸ› ï¸ Requisitos
- **Python** 3.10+
- Paquetes:
  - `pandas`, `numpy`
  - `scikit-learn`
  - `matplotlib` y/o `plotly`
  - `seaborn` (opcional para EDA)

InstalaciÃ³n rÃ¡pida:
```bash
pip install -U pandas numpy scikit-learn matplotlib seaborn
# o, si existe:
pip install -r requirements.txt
________________________________________________

CÃ³mo ejecutar
Google Colab

Abre el notebook en notebooks/Proyecto_6_ActivaciondeConceptosyRegresionLineal.ipynb.

AsegÃºrate de que data/Credit.csv estÃ© disponible (subiÃ©ndolo o montando Google Drive).

Ejecuta las celdas en orden: EDA - preprocesamiento - entrenamiento - evaluaciÃ³n - validaciÃ³n de supuestos.

(Opcional) Guarda figuras en outputs/figuras/ y el modelo en outputs/modelos/.
_______________________________________________

Local (Jupyter/VSCode)

git clone https://github.com/cabarcn/activacion-de-Conceptos-y-Regresion-lineal.git
cd activacion-de-Conceptos-y-Regresion-lineal

# (opcional) crear entorno virtual
python -m venv .venv

# Windows:
.venv\Scripts\activate

# Linux/Mac:
source .venv/bin/activate

pip install -r requirements.txt  # si estÃ¡ disponible
# o instala paquetes mÃ­nimos:

pip install -U pandas numpy scikit-learn matplotlib seaborn
# Abre el notebook con Jupyter o VS Code y ejecÃºtalo

__________________________________________________

MÃ©tricas y validaciones

Se reportan (como mÃ­nimo):

RÂ² (coeficiente de determinaciÃ³n)

MAE (Mean Absolute Error)

MSE / RMSE (Root Mean Squared Error)

Validaciones visuales sugeridas:

Real vs. Predicho

DistribuciÃ³n de residuos

QQ-plot (normalidad de residuos)

Residuos vs. predicciones (homocedasticidad)

VIF o correlaciones (para multicolinealidad), si aplica

Incluye al final del notebook una celda que imprima las mÃ©tricas y guarde grÃ¡ficos en outputs/figuras/
____________________________________________________________

PrÃ³ximos pasos (roadmap)

 RegularizaciÃ³n: Ridge / Lasso / ElasticNet y comparaciÃ³n de resultados.

 IngenierÃ­a de variables (interacciones, transformaciones).

 SelecciÃ³n de caracterÃ­sticas (RFE, importancia, VIF).

 ValidaciÃ³n cruzada y curvas de aprendizaje.

 Comparar con baselines: KNN, Ãrboles, Random Forest.

 Exportar el modelo (joblib) a outputs/modelos/.

 ____________________________________________
 ğŸ”¬ Buenas prÃ¡cticas de reproducibilidad

Fijar random_state en train_test_split y en los modelos.

Mantener y versionar requirements.txt.

Documentar supuestos y decisiones del preprocesamiento en el notebook.

Evitar subir datos sensibles o archivos >100 MB (usar Git LFS o almacenamiento externo).

ğŸ¤ Contribuciones

Las mejoras son bienvenidas. Abre un Issue o un Pull Request con propuestas (nuevos grÃ¡ficos, comparaciones de modelos, refactor del pipeline, etc.).

ğŸ“„ Licencia

Uso acadÃ©mico/educativo. Ajusta a la licencia que prefieras (por ejemplo, MIT).

âœï¸ Autor

Cristopher Abarca
Desarrollador / Estudiante de IngenierÃ­a InformÃ¡tica
